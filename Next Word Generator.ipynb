{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0b0c1e-2dc1-4a2c-81d9-0eb0bd3f3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acd17b-900a-4ef6-86df-ba7dc6a69294",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43399c3-0280-48d2-b8f9-39cf5ba5013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\syeda\\OneDrive\\Desktop\\Next word predictor\\tmdb_5000_movies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab44f9e-3399-4772-8499-9e80bd95a663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>220000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9367</td>\n",
       "      <td>[{\"id\": 5616, \"name\": \"united states\\u2013mexi...</td>\n",
       "      <td>es</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>El Mariachi just wants to play his guitar and ...</td>\n",
       "      <td>14.269792</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"MX\", \"name\": \"Mexico\"}, {\"iso...</td>\n",
       "      <td>1992-09-04</td>\n",
       "      <td>2040920</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>He didn't come looking for trouble, but troubl...</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>6.6</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>9000</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72766</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>A newlywed couple's honeymoon is upended by th...</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2011-12-26</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>A newlywed couple's honeymoon is upended by th...</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...</td>\n",
       "      <td>http://www.hallmarkchannel.com/signedsealeddel...</td>\n",
       "      <td>231617</td>\n",
       "      <td>[{\"id\": 248, \"name\": \"date\"}, {\"id\": 699, \"nam...</td>\n",
       "      <td>en</td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>\"Signed, Sealed, Delivered\" introduces a dedic...</td>\n",
       "      <td>1.444476</td>\n",
       "      <td>[{\"name\": \"Front Street Pictures\", \"id\": 3958}...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://shanghaicalling.com/</td>\n",
       "      <td>126186</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>When ambitious New York attorney Sam is sent t...</td>\n",
       "      <td>0.857008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>A New Yorker in Shanghai</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 99, \"name\": \"Documentary\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25975</td>\n",
       "      <td>[{\"id\": 1523, \"name\": \"obsession\"}, {\"id\": 224...</td>\n",
       "      <td>en</td>\n",
       "      <td>My Date with Drew</td>\n",
       "      <td>Ever since the second grade when he first saw ...</td>\n",
       "      <td>1.929883</td>\n",
       "      <td>[{\"name\": \"rusty bear entertainment\", \"id\": 87...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2005-08-05</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My Date with Drew</td>\n",
       "      <td>6.3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4803 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget                                             genres  \\\n",
       "0     237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1     300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2     245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3     250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4     260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "...         ...                                                ...   \n",
       "4798     220000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4799       9000  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
       "4800          0  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...   \n",
       "4801          0                                                 []   \n",
       "4802          0                [{\"id\": 99, \"name\": \"Documentary\"}]   \n",
       "\n",
       "                                               homepage      id  \\\n",
       "0                           http://www.avatarmovie.com/   19995   \n",
       "1          http://disney.go.com/disneypictures/pirates/     285   \n",
       "2           http://www.sonypictures.com/movies/spectre/  206647   \n",
       "3                    http://www.thedarkknightrises.com/   49026   \n",
       "4                  http://movies.disney.com/john-carter   49529   \n",
       "...                                                 ...     ...   \n",
       "4798                                                NaN    9367   \n",
       "4799                                                NaN   72766   \n",
       "4800  http://www.hallmarkchannel.com/signedsealeddel...  231617   \n",
       "4801                        http://shanghaicalling.com/  126186   \n",
       "4802                                                NaN   25975   \n",
       "\n",
       "                                               keywords original_language  \\\n",
       "0     [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1     [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2     [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "3     [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
       "4     [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "...                                                 ...               ...   \n",
       "4798  [{\"id\": 5616, \"name\": \"united states\\u2013mexi...                es   \n",
       "4799                                                 []                en   \n",
       "4800  [{\"id\": 248, \"name\": \"date\"}, {\"id\": 699, \"nam...                en   \n",
       "4801                                                 []                en   \n",
       "4802  [{\"id\": 1523, \"name\": \"obsession\"}, {\"id\": 224...                en   \n",
       "\n",
       "                                original_title  \\\n",
       "0                                       Avatar   \n",
       "1     Pirates of the Caribbean: At World's End   \n",
       "2                                      Spectre   \n",
       "3                        The Dark Knight Rises   \n",
       "4                                  John Carter   \n",
       "...                                        ...   \n",
       "4798                               El Mariachi   \n",
       "4799                                 Newlyweds   \n",
       "4800                 Signed, Sealed, Delivered   \n",
       "4801                          Shanghai Calling   \n",
       "4802                         My Date with Drew   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "0     In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1     Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2     A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "3     Following the death of District Attorney Harve...  112.312950   \n",
       "4     John Carter is a war-weary, former military ca...   43.926995   \n",
       "...                                                 ...         ...   \n",
       "4798  El Mariachi just wants to play his guitar and ...   14.269792   \n",
       "4799  A newlywed couple's honeymoon is upended by th...    0.642552   \n",
       "4800  \"Signed, Sealed, Delivered\" introduces a dedic...    1.444476   \n",
       "4801  When ambitious New York attorney Sam is sent t...    0.857008   \n",
       "4802  Ever since the second grade when he first saw ...    1.929883   \n",
       "\n",
       "                                   production_companies  \\\n",
       "0     [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1     [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2     [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "3     [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "4           [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "...                                                 ...   \n",
       "4798           [{\"name\": \"Columbia Pictures\", \"id\": 5}]   \n",
       "4799                                                 []   \n",
       "4800  [{\"name\": \"Front Street Pictures\", \"id\": 3958}...   \n",
       "4801                                                 []   \n",
       "4802  [{\"name\": \"rusty bear entertainment\", \"id\": 87...   \n",
       "\n",
       "                                   production_countries release_date  \\\n",
       "0     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10   \n",
       "1     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   \n",
       "2     [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   \n",
       "3     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16   \n",
       "4     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   \n",
       "...                                                 ...          ...   \n",
       "4798  [{\"iso_3166_1\": \"MX\", \"name\": \"Mexico\"}, {\"iso...   1992-09-04   \n",
       "4799                                                 []   2011-12-26   \n",
       "4800  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2013-10-13   \n",
       "4801  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-05-03   \n",
       "4802  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2005-08-05   \n",
       "\n",
       "         revenue  runtime                                   spoken_languages  \\\n",
       "0     2787965087    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "1      961000000    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "2      880674609    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...   \n",
       "3     1084939099    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4      284139100    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "...          ...      ...                                                ...   \n",
       "4798     2040920     81.0      [{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]   \n",
       "4799           0     85.0                                                 []   \n",
       "4800           0    120.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4801           0     98.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4802           0     90.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "\n",
       "        status                                            tagline  \\\n",
       "0     Released                        Enter the World of Pandora.   \n",
       "1     Released     At the end of the world, the adventure begins.   \n",
       "2     Released                              A Plan No One Escapes   \n",
       "3     Released                                    The Legend Ends   \n",
       "4     Released               Lost in our world, found in another.   \n",
       "...        ...                                                ...   \n",
       "4798  Released  He didn't come looking for trouble, but troubl...   \n",
       "4799  Released  A newlywed couple's honeymoon is upended by th...   \n",
       "4800  Released                                                NaN   \n",
       "4801  Released                           A New Yorker in Shanghai   \n",
       "4802  Released                                                NaN   \n",
       "\n",
       "                                         title  vote_average  vote_count  \n",
       "0                                       Avatar           7.2       11800  \n",
       "1     Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                      Spectre           6.3        4466  \n",
       "3                        The Dark Knight Rises           7.6        9106  \n",
       "4                                  John Carter           6.1        2124  \n",
       "...                                        ...           ...         ...  \n",
       "4798                               El Mariachi           6.6         238  \n",
       "4799                                 Newlyweds           5.9           5  \n",
       "4800                 Signed, Sealed, Delivered           7.0           6  \n",
       "4801                          Shanghai Calling           5.7           7  \n",
       "4802                         My Date with Drew           6.3          16  \n",
       "\n",
       "[4803 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90da9797-3105-4f6f-b7fc-f4d6f187c1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3  250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4  260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "3            http://www.thedarkknightrises.com/   49026   \n",
       "4          http://movies.disney.com/john-carter   49529   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
       "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "3  Following the death of District Attorney Harve...  112.312950   \n",
       "4  John Carter is a war-weary, former military ca...   43.926995   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
       "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
       "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16  1084939099   \n",
       "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   284139100   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "3    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "4    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "3                                 The Legend Ends   \n",
       "4            Lost in our world, found in another.   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  \n",
       "3                     The Dark Knight Rises           7.6        9106  \n",
       "4                               John Carter           6.1        2124  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c24fd36-14b3-4d1f-8893-35ad4c69140e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>220000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9367</td>\n",
       "      <td>[{\"id\": 5616, \"name\": \"united states\\u2013mexi...</td>\n",
       "      <td>es</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>El Mariachi just wants to play his guitar and ...</td>\n",
       "      <td>14.269792</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"MX\", \"name\": \"Mexico\"}, {\"iso...</td>\n",
       "      <td>1992-09-04</td>\n",
       "      <td>2040920</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>He didn't come looking for trouble, but troubl...</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>6.6</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>9000</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72766</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>A newlywed couple's honeymoon is upended by th...</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2011-12-26</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>A newlywed couple's honeymoon is upended by th...</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...</td>\n",
       "      <td>http://www.hallmarkchannel.com/signedsealeddel...</td>\n",
       "      <td>231617</td>\n",
       "      <td>[{\"id\": 248, \"name\": \"date\"}, {\"id\": 699, \"nam...</td>\n",
       "      <td>en</td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>\"Signed, Sealed, Delivered\" introduces a dedic...</td>\n",
       "      <td>1.444476</td>\n",
       "      <td>[{\"name\": \"Front Street Pictures\", \"id\": 3958}...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://shanghaicalling.com/</td>\n",
       "      <td>126186</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>When ambitious New York attorney Sam is sent t...</td>\n",
       "      <td>0.857008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>A New Yorker in Shanghai</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 99, \"name\": \"Documentary\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25975</td>\n",
       "      <td>[{\"id\": 1523, \"name\": \"obsession\"}, {\"id\": 224...</td>\n",
       "      <td>en</td>\n",
       "      <td>My Date with Drew</td>\n",
       "      <td>Ever since the second grade when he first saw ...</td>\n",
       "      <td>1.929883</td>\n",
       "      <td>[{\"name\": \"rusty bear entertainment\", \"id\": 87...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2005-08-05</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My Date with Drew</td>\n",
       "      <td>6.3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "4798  220000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4799    9000  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
       "4800       0  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...   \n",
       "4801       0                                                 []   \n",
       "4802       0                [{\"id\": 99, \"name\": \"Documentary\"}]   \n",
       "\n",
       "                                               homepage      id  \\\n",
       "4798                                                NaN    9367   \n",
       "4799                                                NaN   72766   \n",
       "4800  http://www.hallmarkchannel.com/signedsealeddel...  231617   \n",
       "4801                        http://shanghaicalling.com/  126186   \n",
       "4802                                                NaN   25975   \n",
       "\n",
       "                                               keywords original_language  \\\n",
       "4798  [{\"id\": 5616, \"name\": \"united states\\u2013mexi...                es   \n",
       "4799                                                 []                en   \n",
       "4800  [{\"id\": 248, \"name\": \"date\"}, {\"id\": 699, \"nam...                en   \n",
       "4801                                                 []                en   \n",
       "4802  [{\"id\": 1523, \"name\": \"obsession\"}, {\"id\": 224...                en   \n",
       "\n",
       "                 original_title  \\\n",
       "4798                El Mariachi   \n",
       "4799                  Newlyweds   \n",
       "4800  Signed, Sealed, Delivered   \n",
       "4801           Shanghai Calling   \n",
       "4802          My Date with Drew   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "4798  El Mariachi just wants to play his guitar and ...   14.269792   \n",
       "4799  A newlywed couple's honeymoon is upended by th...    0.642552   \n",
       "4800  \"Signed, Sealed, Delivered\" introduces a dedic...    1.444476   \n",
       "4801  When ambitious New York attorney Sam is sent t...    0.857008   \n",
       "4802  Ever since the second grade when he first saw ...    1.929883   \n",
       "\n",
       "                                   production_companies  \\\n",
       "4798           [{\"name\": \"Columbia Pictures\", \"id\": 5}]   \n",
       "4799                                                 []   \n",
       "4800  [{\"name\": \"Front Street Pictures\", \"id\": 3958}...   \n",
       "4801                                                 []   \n",
       "4802  [{\"name\": \"rusty bear entertainment\", \"id\": 87...   \n",
       "\n",
       "                                   production_countries release_date  revenue  \\\n",
       "4798  [{\"iso_3166_1\": \"MX\", \"name\": \"Mexico\"}, {\"iso...   1992-09-04  2040920   \n",
       "4799                                                 []   2011-12-26        0   \n",
       "4800  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2013-10-13        0   \n",
       "4801  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-05-03        0   \n",
       "4802  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2005-08-05        0   \n",
       "\n",
       "      runtime                               spoken_languages    status  \\\n",
       "4798     81.0  [{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]  Released   \n",
       "4799     85.0                                             []  Released   \n",
       "4800    120.0       [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "4801     98.0       [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "4802     90.0       [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "\n",
       "                                                tagline  \\\n",
       "4798  He didn't come looking for trouble, but troubl...   \n",
       "4799  A newlywed couple's honeymoon is upended by th...   \n",
       "4800                                                NaN   \n",
       "4801                           A New Yorker in Shanghai   \n",
       "4802                                                NaN   \n",
       "\n",
       "                          title  vote_average  vote_count  \n",
       "4798                El Mariachi           6.6         238  \n",
       "4799                  Newlyweds           5.9           5  \n",
       "4800  Signed, Sealed, Delivered           7.0           6  \n",
       "4801           Shanghai Calling           5.7           7  \n",
       "4802          My Date with Drew           6.3          16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3c7d39-9f4c-47af-8325-a666b497d370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Records:  4803\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Records: \", data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c827f1-8929-421f-be66-5e9dd3ba76e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of fields:  20\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of fields: \", data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3ab98-5901-43b8-88a6-b4bd4e4e8487",
   "metadata": {},
   "source": [
    "## Display only original titles of various movies and preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f7ce80-9d64-4fa9-8f69-7d8b03629ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         Avatar\n",
       "1       Pirates of the Caribbean: At World's End\n",
       "2                                        Spectre\n",
       "3                          The Dark Knight Rises\n",
       "4                                    John Carter\n",
       "                          ...                   \n",
       "4798                                 El Mariachi\n",
       "4799                                   Newlyweds\n",
       "4800                   Signed, Sealed, Delivered\n",
       "4801                            Shanghai Calling\n",
       "4802                           My Date with Drew\n",
       "Name: title, Length: 4803, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c89249-a2dd-4aad-860d-f81af35ba3ef",
   "metadata": {},
   "source": [
    "#### Removing unwanted characters and words in titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e303e760-e26c-476a-8400-a2c54017853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title'] = data['title'].apply(lambda x: x.replace(r'\\xao', 'u'))\n",
    "data['title'] = data['title'].apply(lambda x: x.replace(r'\\u200a', ' '))\n",
    "data['title'] = data['title'].apply(lambda x: x.replace(r'\\xao', 'u'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d293ed6-6246-41b8-a20d-cbd4007c3386",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6ef7c56-e476-4b10-8a44-6eba21a1f274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total no. of words:  4798\n",
      "word: ID\n",
      "----------------\n",
      "<oov>:  1\n",
      "Strong:  1429\n",
      "And:  5\n",
      "Pirates:  217\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(data['title'])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(\" Total no. of words: \", total_words)\n",
    "print(\"word: ID\")\n",
    "print(\"----------------\")\n",
    "print(\"<oov>: \", tokenizer.word_index['<oov>'])\n",
    "print(\"Strong: \", tokenizer.word_index['strong'])\n",
    "print(\"And: \", tokenizer.word_index['and'])\n",
    "print(\"Pirates: \", tokenizer.word_index['pirates'])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58125fc3-e4df-4430-8301-45ef5ff740ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input sequences:  8599\n"
     ]
    }
   ],
   "source": [
    "input_sequences = []\n",
    "for line in data['title']:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequences = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequences)\n",
    "\n",
    "print(\"Total input sequences: \", len(input_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cdd130-eae3-42aa-ae69-b4c9335dd466",
   "metadata": {},
   "source": [
    "#### Using padding for making all titles with same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a061413b-088b-419e-b84a-2e4036cf0289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 217,\n",
       "         3,   2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen= max_sequence_len, padding='pre'))\n",
    "input_sequences[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1299a140-a4e9-43f1-9086-dc44c6a6a8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 217,   3,\n",
       "         2, 444])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f134b0b-fed4-479a-a410-6239c55b6bb8",
   "metadata": {},
   "source": [
    "### Preparing the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85fe4557-53da-4647-9ade-12d97d6e869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "072d3d65-6d4b-4f0e-a203-9fb146f6be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0 217   3   2 444  47 445]\n"
     ]
    }
   ],
   "source": [
    "print(xs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25fba275-1d00-4444-929d-b86cd51b2cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "print(labels[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4233e56-f4f1-4572-80d2-fb1aa0e2eb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(ys[6][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39699447-726b-4d07-97e0-e0d64e4fe035",
   "metadata": {},
   "source": [
    "## Bi- LSTM Neural Network Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3dd1b98-611b-46bb-9bd5-db8ecaa11def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\anaconda3\\envs\\tf-new\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "269/269 [==============================] - 23s 45ms/step - loss: 7.5303 - accuracy: 0.0848\n",
      "Epoch 2/50\n",
      "269/269 [==============================] - 11s 39ms/step - loss: 6.4662 - accuracy: 0.1145\n",
      "Epoch 3/50\n",
      "269/269 [==============================] - 11s 42ms/step - loss: 5.4479 - accuracy: 0.1627\n",
      "Epoch 4/50\n",
      "269/269 [==============================] - 12s 45ms/step - loss: 4.2668 - accuracy: 0.2483\n",
      "Epoch 5/50\n",
      "269/269 [==============================] - 11s 41ms/step - loss: 3.2777 - accuracy: 0.3741\n",
      "Epoch 6/50\n",
      "269/269 [==============================] - 11s 43ms/step - loss: 2.5970 - accuracy: 0.4848\n",
      "Epoch 7/50\n",
      "269/269 [==============================] - 12s 45ms/step - loss: 2.1788 - accuracy: 0.5669\n",
      "Epoch 8/50\n",
      "269/269 [==============================] - 12s 45ms/step - loss: 1.8973 - accuracy: 0.6136\n",
      "Epoch 9/50\n",
      "269/269 [==============================] - 11s 41ms/step - loss: 1.7390 - accuracy: 0.6424\n",
      "Epoch 10/50\n",
      "269/269 [==============================] - 12s 46ms/step - loss: 1.6443 - accuracy: 0.6559\n",
      "Epoch 11/50\n",
      "269/269 [==============================] - 12s 45ms/step - loss: 1.5869 - accuracy: 0.6596\n",
      "Epoch 12/50\n",
      "269/269 [==============================] - 12s 44ms/step - loss: 1.5439 - accuracy: 0.6610\n",
      "Epoch 13/50\n",
      "269/269 [==============================] - 11s 42ms/step - loss: 1.5121 - accuracy: 0.6659\n",
      "Epoch 14/50\n",
      "269/269 [==============================] - 13s 48ms/step - loss: 1.4899 - accuracy: 0.6672\n",
      "Epoch 15/50\n",
      "269/269 [==============================] - 13s 49ms/step - loss: 1.4774 - accuracy: 0.6612\n",
      "Epoch 16/50\n",
      "269/269 [==============================] - 13s 48ms/step - loss: 1.4782 - accuracy: 0.6625\n",
      "Epoch 17/50\n",
      "269/269 [==============================] - 12s 44ms/step - loss: 1.4967 - accuracy: 0.6588\n",
      "Epoch 18/50\n",
      "269/269 [==============================] - 11s 42ms/step - loss: 1.6713 - accuracy: 0.6190\n",
      "Epoch 19/50\n",
      "269/269 [==============================] - 12s 46ms/step - loss: 2.1000 - accuracy: 0.5373\n",
      "Epoch 20/50\n",
      "269/269 [==============================] - 13s 47ms/step - loss: 1.8934 - accuracy: 0.5800\n",
      "Epoch 21/50\n",
      "269/269 [==============================] - 15s 56ms/step - loss: 1.6243 - accuracy: 0.6373\n",
      "Epoch 22/50\n",
      "269/269 [==============================] - 12s 44ms/step - loss: 1.5063 - accuracy: 0.6594\n",
      "Epoch 23/50\n",
      "269/269 [==============================] - 12s 46ms/step - loss: 1.4418 - accuracy: 0.6678\n",
      "Epoch 24/50\n",
      "269/269 [==============================] - 13s 47ms/step - loss: 1.4134 - accuracy: 0.6695\n",
      "Epoch 25/50\n",
      "269/269 [==============================] - 13s 47ms/step - loss: 1.3985 - accuracy: 0.6646\n",
      "Epoch 26/50\n",
      "269/269 [==============================] - 12s 44ms/step - loss: 1.3835 - accuracy: 0.6679\n",
      "Epoch 27/50\n",
      "269/269 [==============================] - 12s 44ms/step - loss: 1.3736 - accuracy: 0.6680\n",
      "Epoch 28/50\n",
      "269/269 [==============================] - 13s 47ms/step - loss: 1.3711 - accuracy: 0.6674\n",
      "Epoch 29/50\n",
      "269/269 [==============================] - 17s 65ms/step - loss: 1.3658 - accuracy: 0.6705\n",
      "Epoch 30/50\n",
      "269/269 [==============================] - 14s 54ms/step - loss: 1.3742 - accuracy: 0.6661\n",
      "Epoch 31/50\n",
      "269/269 [==============================] - 14s 53ms/step - loss: 1.5740 - accuracy: 0.6467\n",
      "Epoch 37/50\n",
      "269/269 [==============================] - 14s 51ms/step - loss: 1.4722 - accuracy: 0.6618\n",
      "Epoch 38/50\n",
      "269/269 [==============================] - 13s 50ms/step - loss: 1.4221 - accuracy: 0.6660\n",
      "Epoch 39/50\n",
      "269/269 [==============================] - 14s 52ms/step - loss: 1.3982 - accuracy: 0.6647\n",
      "Epoch 40/50\n",
      "269/269 [==============================] - 12s 46ms/step - loss: 1.3783 - accuracy: 0.6682\n",
      "Epoch 41/50\n",
      "269/269 [==============================] - 12s 44ms/step - loss: 1.3674 - accuracy: 0.6681\n",
      "Epoch 42/50\n",
      "269/269 [==============================] - 13s 47ms/step - loss: 1.3647 - accuracy: 0.6682\n",
      "Epoch 43/50\n",
      "269/269 [==============================] - 14s 53ms/step - loss: 1.3596 - accuracy: 0.6660\n",
      "Epoch 44/50\n",
      "269/269 [==============================] - 13s 48ms/step - loss: 1.3550 - accuracy: 0.6683\n",
      "Epoch 45/50\n",
      "269/269 [==============================] - 12s 45ms/step - loss: 1.3590 - accuracy: 0.6687\n",
      "Epoch 46/50\n",
      "269/269 [==============================] - 15s 55ms/step - loss: 1.3690 - accuracy: 0.6652\n",
      "Epoch 47/50\n",
      "269/269 [==============================] - 14s 53ms/step - loss: 1.3957 - accuracy: 0.6622\n",
      "Epoch 48/50\n",
      "269/269 [==============================] - 12s 46ms/step - loss: 1.5400 - accuracy: 0.6380\n",
      "Epoch 49/50\n",
      "269/269 [==============================] - 13s 48ms/step - loss: 1.9571 - accuracy: 0.5705\n",
      "Epoch 50/50\n",
      "269/269 [==============================] - 13s 47ms/step - loss: 1.8517 - accuracy: 0.5839\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length = max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation = 'softmax'))\n",
    "adam = Adam(lr = 0.01)\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer = adam, metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d4479-6025-4d19-9b9d-61c323df14ad",
   "metadata": {},
   "source": [
    "# Predicting the next word of title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6679fc2-6e5b-480d-9315-410bd9720d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caribbean\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have already defined and trained your model\n",
    "\n",
    "# ...\n",
    "\n",
    "token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted_probs = model.predict(token_list, verbose=0)\n",
    "\n",
    "# Extract the index of the word with the highest probability\n",
    "predicted_index = np.argmax(predicted_probs)\n",
    "\n",
    "# Find the corresponding word using the tokenizer's word index\n",
    "output_word = \"\"\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted_index:\n",
    "        output_word = word\n",
    "        break\n",
    "\n",
    "print(output_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "609a1471-b5f2-4926-83fb-22fee88fa8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pirates of the caribbean fathers world's end\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \" Pirates of the\"\n",
    "next_words = 4\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a7e9561-1a82-477f-be16-2c40a704bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Dark hours 40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \" The Dark\"\n",
    "next_words = 2\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e21d226-8850-42c0-a767-5477d74d310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pirates of the caribbean\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \" Pirates of the\"\n",
    "next_words = 1\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac0f6ff3-10d8-4a8b-bac2-dbae6c938e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Dark Knight rises\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \" The Dark Knight\"\n",
    "next_words = 1\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e399f5cb-dd81-4a73-83be-fd485d0a2965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shangai intentions\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \" Shangai\"\n",
    "next_words = 1\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f80dba3-d6f8-4f64-9ff4-8dccfaebfa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed, Sealed,  delivered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \"Signed, Sealed, \"\n",
    "next_words = 1\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68b9eccd-e2bd-40a0-bafb-f2dde2963121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Date with drew\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \"My Date with\"\n",
    "next_words = 1\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5abea91-ef1b-4351-a2aa-b4d2e2c938c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El rey de najayo najayo najayo\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \"El\"\n",
    "next_words = 5\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "724febde-8ec9-440a-a08a-fe7fd9c6e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newlyweds intentions\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \"Newlyweds\"\n",
    "next_words = 1\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "077cc54a-e4e7-486e-8468-ae30f91cf854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newlyweds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \"Newlyweds\"\n",
    "next_words = 0\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3991c244-53f6-489d-a893-ce97408545d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai Calling\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \"Shanghai Calling\"\n",
    "next_words = 0\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c800cc1e-9d37-4643-8849-43946acd8a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai Calling love mandy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = \"Shanghai Calling\"\n",
    "next_words = 2\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list, verbose=0)\n",
    "    \n",
    "    # Extract the index of the word with the highest probability\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    # Find the corresponding word using the tokenizer's word index\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    \n",
    "    text += \" \" + output_word\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4f83a-da99-4896-9be1-711acb3300cf",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b53a5985-0f06-4e39-a8db-5ac04326b186",
   "metadata": {},
   "source": [
    "Here in this Next word Generator or prediction we use Deep learning and Machine learning algorithms. Deep Learning in NLP has several useful applications among them next-word prediction is one. We can capture the sequencial dependencies in text data and produce pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
